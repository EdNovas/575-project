{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ptz-jfqnvBuA"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "file_ids = [\n",
        "    \"1k5YrGPTzRTw1MsnLzkLFblTRplfdHkj_\",\n",
        "    \"1kM96FBZb9KrmUqvrJZnCzIVdf-dbJCu8\",\n",
        "    \"1kGXy1t1myzHzRIdFbRCAO2jYhoQXiZwV\",\n",
        "    \"1kUosa6wg9T2M5aen8EwvyUotmywWqw-C\",\n",
        "    \"1kPEPJQ4CqV-cCo6p8VVxhribkpOP4UJh\",\n",
        "    \"1kNA7qmZtGByKg-v36jS91_ziJ6RzIuCM\",\n",
        "    \"1Rmy10QBMkeKMbirJ3VqilrT81ix6T9uk\",\n",
        "    \"1mU9YVr99C7E5hdys5zPQa5FnvplV8jWv\"\n",
        "]\n",
        "\n",
        "for file_id in file_ids:\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    subprocess.run([\"gdown\", url])\n",
        "\n",
        "# Define your local directory where the zip file is located.\n",
        "local_path = \"\"  # Replace with your actual path\n",
        "zip_file_path = os.path.join(local_path, \"lyrics.zip\")\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(local_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVwRwljqvgk9"
      },
      "outputs": [],
      "source": [
        "# paste the artist and song name here\n",
        "# song_title = \"song_title\"\n",
        "# artist = \"artist\"\n",
        "song_title = 'Demons'\n",
        "artist = 'Imagine Dragons'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY2KgEk14Siq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWlBZM4Bvfe1",
        "outputId": "d270a50d-ee0e-43d9-df6b-76d7db155d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found 2 matching record(s) for the recognized song.\n",
            "\n",
            "Basic Music Information for the recognized track:\n",
            "              spotifyid popularity danceability              energy  key mode  \\\n",
            "49578  S4Oy1aU6jaz87NDi       27.0        0.515  0.7879999999999999  3.0  1.0   \n",
            "83818  lZDk11KaRskQqhWf       70.0        0.505                0.71  3.0  1.0   \n",
            "\n",
            "      valence              tempo            genres  \\\n",
            "49578   0.276            102.002  remix,indie rock   \n",
            "83818   0.428  89.93799999999997   rock,indie rock   \n",
            "\n",
            "                                                    tags lang  \\\n",
            "49578                 remix,indie,indie rock,alternative   en   \n",
            "83818  indie,rock,indie rock,alternative,imagine dragons   en   \n",
            "\n",
            "                                 song           artist  \n",
            "49578  Demons (Imagine Dragons Remix)  Imagine Dragons  \n",
            "83818                          Demons  Imagine Dragons  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def read_csv_manual(filepath, delimiter=\"\\t\"):\n",
        "    \"\"\"\n",
        "    Read a CSV file by manually splitting lines and creating a DataFrame.\n",
        "    This function forces the DataFrame to use dtype=object, then converts\n",
        "    all columns to string to avoid the \"Cannot convert numpy.ndarray\" error.\n",
        "    \"\"\"\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.read().splitlines()\n",
        "\n",
        "    # Find the first non-empty line to use as header\n",
        "    header_line = None\n",
        "    for line in lines:\n",
        "        if line.strip():\n",
        "            header_line = line.strip()\n",
        "            break\n",
        "    if header_line is None:\n",
        "        raise ValueError(\"No header found in file: \" + filepath)\n",
        "\n",
        "    # Split the header using whitespace\n",
        "    header = header_line.split(delimiter)\n",
        "    ncols = len(header)\n",
        "\n",
        "    data = []\n",
        "    # Process remaining lines.\n",
        "    for line in lines[1:]:\n",
        "        if not line.strip():\n",
        "            continue\n",
        "        # Use maxsplit to ensure that any extra delimiter in the last field is preserved\n",
        "        row = line.strip().split(delimiter, ncols - 1)\n",
        "        if len(row) < ncols:\n",
        "            row += [\"\"] * (ncols - len(row))\n",
        "        data.append(row)\n",
        "\n",
        "    # Create DataFrame using dtype=object then convert all columns to string.\n",
        "    df = pd.DataFrame(data, columns=header, dtype=object)\n",
        "    return df.astype(str)\n",
        "\n",
        "# Define the local directory where your CSV files are saved.\n",
        "local_path = \"\"\n",
        "\n",
        "# Read CSV files using the new custom reader.\n",
        "df_genres = read_csv_manual(os.path.join(local_path, \"id_genres.csv\"), delimiter=\"\\t\")\n",
        "df_info   = read_csv_manual(os.path.join(local_path, \"id_information.csv\"), delimiter=\"\\t\")\n",
        "df_meta   = read_csv_manual(os.path.join(local_path, \"id_metadata.csv\"), delimiter=\"\\t\")\n",
        "df_lang  = read_csv_manual(os.path.join(local_path, \"id_lang.csv\"), delimiter=\"\\t\")\n",
        "df_tags   = read_csv_manual(os.path.join(local_path, \"id_tags.csv\"), delimiter=\"\\t\")\n",
        "\n",
        "# Verify that the data loaded correctly.\n",
        "# print(\"df_genres:\")\n",
        "# print(df_genres.head(), \"\\n\")\n",
        "\n",
        "# print(\"df_info:\")\n",
        "# print(df_info.head(), \"\\n\")\n",
        "\n",
        "# print(\"df_meta:\")\n",
        "# print(df_meta.head(), \"\\n\")\n",
        "\n",
        "# print(\"df_lang:\")\n",
        "# print(df_lang.head(), \"\\n\")\n",
        "\n",
        "# print(\"df_tags:\")\n",
        "# print(df_tags.head(), \"\\n\")\n",
        "\n",
        "# --- Merge the DataFrames ---\n",
        "# the common key across files is \"id\".\n",
        "df_merge = pd.merge(df_info, df_meta, on=\"id\", how=\"left\")\n",
        "df_merge = pd.merge(df_merge, df_lang, on=\"id\", how=\"left\")\n",
        "df_merge = pd.merge(df_merge, df_genres, on=\"id\", how=\"left\")\n",
        "df_merge = pd.merge(df_merge, df_tags, on=\"id\", how=\"left\")\n",
        "\n",
        "df_merge.to_csv(\"processed_data.csv\", index=False, encoding=\"utf-8\")\n",
        "# print(\"Merged DataFrame columns:\")\n",
        "# print(df_merge.columns.tolist())\n",
        "\n",
        "# --- Filter for the Shazam-Recognized Song ---\n",
        "recognized_title = song_title  # Song title recognized by Shazam\n",
        "recognized_artist = artist   # Artist recognized by Shazam\n",
        "\n",
        "filtered = df_merge[\n",
        "    (df_merge['song'].str.lower().str.contains(recognized_title.lower(), na=False)) &\n",
        "    (df_merge['artist'].str.lower().str.contains(recognized_artist.lower(), na=False))\n",
        "]\n",
        "\n",
        "print(f\"\\nFound {len(filtered)} matching record(s) for the recognized song.\")\n",
        "\n",
        "# --- Load Lyrics from Local Files ---\n",
        "# lyrics files are in a local folder \"lyrics\" under /content,\n",
        "# with each file named as \"<id>.txt\".\n",
        "lyrics_folder = os.path.join(local_path, \"lyrics\")\n",
        "\n",
        "def load_lyrics(track_id):\n",
        "    lyrics_file = os.path.join(lyrics_folder, f\"{track_id}.txt\")\n",
        "    if os.path.exists(lyrics_file):\n",
        "        with open(lyrics_file, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    else:\n",
        "        return \"Lyrics not available.\"\n",
        "\n",
        "if not filtered.empty:\n",
        "    result_df = filtered.copy()\n",
        "    result_df['lyrics'] = result_df['id'].apply(load_lyrics)\n",
        "\n",
        "    # --- Select and Rename Desired Columns ---\n",
        "    # Desired columns: lyrics, spotifyid, popularity, danceability, energy,\n",
        "    # key, mode, valence, tempo, genres, tags, lang, song, artist.\n",
        "    cols_to_show = {\n",
        "        \"id\": \"spotifyid\",   # from df_audio\n",
        "        \"popularity\": \"popularity\",  # from df_audio\n",
        "        \"danceability\": \"danceability\",  # from df_audio\n",
        "        \"energy\": \"energy\",              # from df_audio\n",
        "        \"key\": \"key\",                    # from df_audio\n",
        "        \"mode\": \"mode\",                  # from df_audio\n",
        "        \"valence\": \"valence\",            # from df_audio\n",
        "        \"tempo\": \"tempo\",                # from df_audio\n",
        "        \"genres\": \"genres\",              # from df_genres\n",
        "        \"tags\": \"tags\",                  # from df_tags\n",
        "        \"lang\": \"lang\",                  # from df_lang\n",
        "        \"song\": \"song\",                  # from df_info\n",
        "        \"artist\": \"artist\"               # from df_info\n",
        "    }\n",
        "    final_df = result_df[list(cols_to_show.keys())].rename(columns=cols_to_show)\n",
        "\n",
        "    print(\"\\nBasic Music Information for the recognized track:\")\n",
        "    print(final_df)\n",
        "\n",
        "else:\n",
        "    print(\"No matching record found in the Music4all database for the recognized song.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du4QTMDzvwy_",
        "outputId": "00a1c550-8ed5-44d6-d2a3-8ca414ff6e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Most Accurate Match:\n",
            "id                                               lZDk11KaRskQqhWf\n",
            "artist                                            Imagine Dragons\n",
            "song                                                       Demons\n",
            "album_name                                          Night Visions\n",
            "spotify_id                                 3LlAyCYU26dvFZBDUIMb7a\n",
            "popularity                                                   70.0\n",
            "release                                                      2012\n",
            "danceability                                                0.505\n",
            "energy                                                       0.71\n",
            "key                                                           3.0\n",
            "mode                                                          1.0\n",
            "valence                                                     0.428\n",
            "tempo                                           89.93799999999997\n",
            "duration_ms                                                175200\n",
            "lang                                                           en\n",
            "genres                                            rock,indie rock\n",
            "tags            indie,rock,indie rock,alternative,imagine dragons\n",
            "Name: 83818, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Further refine the filtered DataFrame to select the most accurate match.\n",
        "# We assume that the best match is the one where the song column (after stripping and lowercasing)\n",
        "# exactly equals the recognized title, e.g., \"believer\" (ignoring any remix annotations).\n",
        "\n",
        "# Create a new column with normalized song names.\n",
        "filtered = filtered.copy()  # ensure you're working with an explicit copy\n",
        "filtered.loc[:, \"song_normalized\"] = filtered[\"song\"].str.strip().str.lower()\n",
        "\n",
        "\n",
        "# Normalize the recognized title.\n",
        "recognized_title_norm = recognized_title.strip().lower()\n",
        "\n",
        "# Filter for exact matches.\n",
        "exact_matches = filtered[filtered[\"song_normalized\"] == recognized_title_norm]\n",
        "\n",
        "if not exact_matches.empty:\n",
        "    # If there is an exact match, choose the first one.\n",
        "    best_match = exact_matches.iloc[0]\n",
        "else:\n",
        "    # Otherwise, as a fallback, choose the record with the highest popularity.\n",
        "    best_match = filtered.sort_values(by=\"popularity\", ascending=False).iloc[0]\n",
        "\n",
        "# Drop the helper column before displaying.\n",
        "best_match = best_match.drop(\"song_normalized\")\n",
        "song_id = best_match[\"id\"]\n",
        "spotify_track_id = best_match[\"spotify_id\"]\n",
        "\n",
        "print(\"\\nMost Accurate Match:\")\n",
        "print(best_match)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PANSbMRBMe4",
        "outputId": "a31738be-d047-4a84-8372-383f8a1a63ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "When the days are cold and the cards all fold\n",
            "And the saints we see are all made of gold\n",
            "When your dreams all fail and the ones we hail\n",
            "Are the worst of all and the blood's run stale\n",
            "\n",
            "I want to hide the truth, I want to shelter you\n",
            "But with the beast inside, there's nowhere we can hide\n",
            "No matter what we breed, we still are made of greed\n",
            "This is my kingdom come, this is my kingdom come\n",
            "\n",
            "When you feel my heat, look into my eyes\n",
            "It's where my demons hide, it's where my demons hide\n",
            "Don't get too close, it's dark inside\n",
            "It's where my demons hide, it's where my demons hide\n",
            "\n",
            "At the curtain's call is the last of all\n",
            "When the lights fade out, all the sinners crawl\n",
            "So they dug your grave and the masquerade\n",
            "Will come calling out at the mess you made\n",
            "\n",
            "Don't want to let you down, but I am hell bound\n",
            "Though this is all for you I don't want to hide the truth\n",
            "No matter what we breed, we still are made of greed\n",
            "This is my kingdom come, this is my kingdom come\n",
            "\n",
            "When you feel my heat, look into my eyes\n",
            "It's where my demons hide, it's where my demons hide\n",
            "Don't get too close, it's dark inside\n",
            "It's where my demons hide, it's where my demons hide\n",
            "\n",
            "They say it's what you make, I say it's up to fate\n",
            "It's woven in my soul, I need to let you go\n",
            "Your eyes, they shine so bright, I want to save that light\n",
            "I can't escape this now, unless you show me how\n",
            "\n",
            "When you feel my heat, look into my eyes\n",
            "It's where my demons hide, it's where my demons hide\n",
            "Don't get too close, it's dark inside\n",
            "It's where my demons hide, it's where my demons hide\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def load_lyrics_by_id(track_id):\n",
        "    \"\"\"Return the content of the lyrics file that corresponds to track_id from the remote URL.\"\"\"\n",
        "    url = f\"https://test.ednovas.xyz/lyrics/{track_id}.txt\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        return \"Lyrics not available.\"\n",
        "\n",
        "# Example: Load lyrics for a song with ID \"zt91HOTj69exVeyB\"\n",
        "lyrics_content = load_lyrics_by_id(song_id)\n",
        "print(lyrics_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrALyDzMB5Od",
        "outputId": "91b24a7c-4938-4e8e-be69-ad0b84064248"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Br4GL_RezyXB1sbox877injTT1gX4eqJ\n",
            "To: /content/lyrics.txt\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.53k/1.53k [00:00<00:00, 3.04MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "When the days are cold and the cards all fold\n",
            "And the saints we see are all made of gold\n",
            "When your dreams all fail and the ones we hail\n",
            "Are the worst of all and the blood's run stale\n",
            "\n",
            "I want to hide the truth, I want to shelter you\n",
            "But with the beast inside, there's nowhere we can hide\n",
            "No matter what we breed, we still are made of greed\n",
            "This is my kingdom come, this is my kingdom come\n",
            "\n",
            "When you feel my heat, look into my eyes\n",
            "It's where my demons hide, it's where my demons hide\n",
            "Don't get too close, it's dark inside\n",
            "It's where my demons hide, it's where my demons hide\n",
            "\n",
            "At the curtain's call is the last of all\n",
            "When the lights fade out, all the sinners crawl\n",
            "So they dug your grave and the masquerade\n",
            "Will come calling out at the mess you made\n",
            "\n",
            "Don't want to let you down, but I am hell bound\n",
            "Though this is all for you I don't want to hide the truth\n",
            "No matter what we breed, we still are made of greed\n",
            "This is my kingdom come, this is my kingdom come\n",
            "\n",
            "When you feel my heat, look into my eyes\n",
            "It's where my demons hide, it's where my demons hide\n",
            "Don't get too close, it's dark inside\n",
            "It's where my demons hide, it's where my demons hide\n",
            "\n",
            "They say it's what you make, I say it's up to fate\n",
            "It's woven in my soul, I need to let you go\n",
            "Your eyes, they shine so bright, I want to save that light\n",
            "I can't escape this now, unless you show me how\n",
            "\n",
            "When you feel my heat, look into my eyes\n",
            "It's where my demons hide, it's where my demons hide\n",
            "Don't get too close, it's dark inside\n",
            "It's where my demons hide, it's where my demons hide\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# !pip install gdown\n",
        "import gdown\n",
        "# Convert the shared link to a direct download link by using the file ID.\n",
        "url = \"https://drive.google.com/uc?id=1Br4GL_RezyXB1sbox877injTT1gX4eqJ\"\n",
        "output = \"lyrics.txt\"\n",
        "\n",
        "# Download the file\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Read the file's content into the variable 'lyrics'\n",
        "with open(output, 'r', encoding='utf-8') as file:\n",
        "    lyrics = file.read()\n",
        "\n",
        "# Print the content of the file\n",
        "print(lyrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi2yFx494OUk",
        "outputId": "95fe2929-9c08-409a-fd70-e095e28337b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Predicted Tags: ['pop', 'rock']\n",
            " Predicted Mood: NEGATIVE (0.98)\n",
            " Extracted Keywords: ['dreams fail', 'fold saints', 'cards cold', 'greed kingdom', 'dreams gold']\n",
            "\n",
            " Micro F1 Score: 0.9373\n",
            " Hamming Loss: 0.0023\n",
            " Precision Micro: 1.0000\n",
            " Recall Micro: 0.8821\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[INFO] Model saved to /content/drive/MyDrive/music4all/lyric_classifier_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# !pip install keybert\n",
        "import re\n",
        "import nltk\n",
        "import requests\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import f1_score,hamming_loss,precision_score,recall_score\n",
        "from transformers import pipeline as hf_pipeline\n",
        "import numpy as np\n",
        "from keybert import KeyBERT\n",
        "\n",
        "# Download NLTK stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Use KeyBERT for keyword extraction\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "def preprocess_lyrics(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Sample training data\n",
        "df_sample = df_merge.dropna(subset=[\"tags\"]).sample(n=100, random_state=42)\n",
        "df_sample[\"lyrics\"] = df_sample[\"id\"].apply(load_lyrics_by_id)\n",
        "df_sample = df_sample.dropna(subset=[\"lyrics\"])\n",
        "\n",
        "df_sample[\"tags_list\"] = df_sample[\"tags\"].apply(lambda x: x.split(\",\") if isinstance(x, str) else [])\n",
        "df_sample = df_sample[df_sample[\"tags_list\"].apply(len) > 0]\n",
        "\n",
        "# Preprocesses lyrics\n",
        "df_sample[\"clean_lyrics\"] = df_sample[\"lyrics\"].apply(preprocess_lyrics)\n",
        "\n",
        "X = df_sample[\"clean_lyrics\"]\n",
        "y = df_sample[\"tags_list\"]\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_bin = mlb.fit_transform(y)\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
        "    (\"clf\", MultiOutputClassifier(RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)))\n",
        "])\n",
        "\n",
        "pipeline.fit(X, y_bin)\n",
        "\n",
        "# Keyword extraction using KeyBERT\n",
        "def extract_keywords(lyrics_text, top_n=5):\n",
        "    keywords = kw_model.extract_keywords(lyrics_text, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=top_n)\n",
        "    normalized_keywords = {\" \".join(sorted(set(kw[0].split()))) for kw in keywords}  # Normalize and remove true duplicates\n",
        "    return list(normalized_keywords)[:top_n]\n",
        "\n",
        "# Predict tags based on lyrics\n",
        "def predict_tags_soft(lyrics_text, threshold=0.1):\n",
        "    tfidf_vec = pipeline.named_steps['tfidf'].transform([lyrics_text])\n",
        "    probas = pipeline.named_steps['clf'].predict_proba(tfidf_vec)\n",
        "\n",
        "    final_tags = []\n",
        "    for i, class_proba in enumerate(probas):\n",
        "        if class_proba[0][1] >= threshold:\n",
        "            final_tags.append(mlb.classes_[i])\n",
        "    return final_tags\n",
        "\n",
        "# Initialize sentiment analysis pipeline using a pre-trained model\n",
        "sentiment_pipeline = hf_pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# def predict_sentiment(lyrics_text):\n",
        "#     result = sentiment_pipeline(lyrics_text[:512])[0]\n",
        "#     return result['label'], result['score']\n",
        "\n",
        "def predict_sentiment(text, max_chunks=3):\n",
        "    chunks = [text[i:i+512] for i in range(0, len(text), 512)]\n",
        "    chunks = chunks[:max_chunks]\n",
        "    results = sentiment_pipeline(chunks)\n",
        "    label_counts = Counter([r[\"label\"] for r in results])\n",
        "    majority = label_counts.most_common(1)[0][0]\n",
        "    avg_score = np.mean([r[\"score\"] for r in results if r[\"label\"] == majority])\n",
        "    return majority, avg_score\n",
        "\n",
        "\n",
        "# Example predictions\n",
        "lyrics_clean = preprocess_lyrics(lyrics)\n",
        "predicted_tags = predict_tags_soft(lyrics_clean, threshold=0.1)\n",
        "sentiment_label, sentiment_score = predict_sentiment(lyrics)\n",
        "keywords = extract_keywords(lyrics_clean, top_n=5)\n",
        "\n",
        "# Print prediction results\n",
        "print(\"\\n Predicted Tags:\", predicted_tags)\n",
        "print(f\" Predicted Mood: {sentiment_label} ({sentiment_score:.2f})\")\n",
        "print(f\" Extracted Keywords: {keywords}\")\n",
        "\n",
        "# After training, make predictions\n",
        "y_pred_bin = pipeline.predict(X)\n",
        "\n",
        "# Model evaluation\n",
        "f1_micro = f1_score(y_bin, y_pred_bin, average=\"micro\")\n",
        "hamming = hamming_loss(y_bin, y_pred_bin)\n",
        "precision_micro = precision_score(y_bin, y_pred_bin, average=\"micro\")\n",
        "recall_micro = recall_score(y_bin, y_pred_bin, average=\"micro\")\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"\\n Micro F1 Score: {f1_micro:.4f}\")\n",
        "print(f\" Hamming Loss: {hamming:.4f}\")\n",
        "print(f\" Precision Micro: {precision_micro:.4f}\")\n",
        "print(f\" Recall Micro: {recall_micro:.4f}\")\n",
        "\n",
        "\n",
        "# # save model\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# model_save_path = \"/content/drive/MyDrive/music4all/lyric_classifier_model.pkl\"\n",
        "\n",
        "# import joblib\n",
        "# joblib.dump({\"pipeline\": pipeline, \"mlb\": mlb}, model_save_path)\n",
        "# print(f\"[INFO] Model saved to {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYyoDCsS743x",
        "outputId": "b69722dd-b0d8-44e0-8904-b9519a0fe462"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# Extraction of Common Utility Functions\n",
        "import re\n",
        "import requests\n",
        "from collections import Counter\n",
        "from keybert import KeyBERT\n",
        "from transformers import pipeline as hf_pipeline\n",
        "import numpy as np\n",
        "import os\n",
        "import gdown\n",
        "import joblib\n",
        "\n",
        "kw_model = KeyBERT()\n",
        "sentiment_pipeline = hf_pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    return \" \".join([w for w in text.split() if len(w) > 2])\n",
        "\n",
        "def extract_keywords(text, top_n=5):\n",
        "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=top_n)\n",
        "    return list({\" \".join(sorted(set(k[0].split()))) for k in keywords})[:top_n]\n",
        "\n",
        "def predict_sentiment(text, max_chunks=1):\n",
        "    chunks = [text[i:i+512] for i in range(0, len(text), 512)][:max_chunks]\n",
        "    results = sentiment_pipeline(chunks)\n",
        "    label_counts = Counter([r[\"label\"] for r in results])\n",
        "    majority = label_counts.most_common(1)[0][0]\n",
        "    avg_score = np.mean([r[\"score\"] for r in results if r[\"label\"] == majority])\n",
        "    return majority, avg_score\n",
        "\n",
        "def predict_tags(text, pipeline, mlb, threshold=0.1):\n",
        "    tfidf_vec = pipeline.named_steps['tfidf'].transform([clean_text(text)])\n",
        "    probas = pipeline.named_steps['clf'].predict_proba(tfidf_vec)\n",
        "    return [mlb.classes_[i] for i, p in enumerate(probas) if p[0][1] >= threshold]\n",
        "\n",
        "def generate_image(prompt, out_path=\"output.png\"):\n",
        "    from openai import OpenAI\n",
        "    import openai\n",
        "    import requests\n",
        "    openai.api_key = \"open_ai_key\"  # Replace with your OpenAI API key\n",
        "    client = OpenAI(api_key=openai.api_key)\n",
        "    response = client.images.generate(\n",
        "        model=\"dall-e-3\",\n",
        "        prompt=prompt,\n",
        "        n=1,\n",
        "        size=\"1024x1024\"\n",
        "    )\n",
        "    img_url = response.data[0].url\n",
        "    img_data = requests.get(img_url).content\n",
        "    with open(out_path, 'wb') as f:\n",
        "        f.write(img_data)\n",
        "    print(f\"[INFO] Image saved to {out_path}\")\n",
        "\n",
        "def load_model(file_id, out_path=\"lyric_classifier_model.pkl\"):\n",
        "    if not os.path.exists(out_path):\n",
        "        print(f\"[INFO] Downloading model from Google Drive...\")\n",
        "        gdown.download(id=file_id, output=out_path, quiet=False, use_cookies=True)\n",
        "    else:\n",
        "        print(f\"[INFO] Model already exists at {out_path}, skipping download.\")\n",
        "\n",
        "    model = joblib.load(out_path)\n",
        "    print(f\"[INFO] Model loaded from {out_path}\")\n",
        "    return model[\"pipeline\"], model[\"mlb\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPFNNhZL77ec",
        "outputId": "fb45f39d-5159-4c63-c3e9-ad3c71c9ff16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Model already exists at lyric_classifier_model.pkl, skipping download.\n",
            "[INFO] Model loaded from lyric_classifier_model.pkl\n",
            "\n",
            "ðŸŽµ 114hOqbAT6B12wCa.txt\n",
            "Tags: []\n",
            "Sentiment: NEGATIVE (0.98)\n",
            "Prompt: ink shut, ink taste, love room, negative, room walk, taste wanted\n",
            "[INFO] Image saved to ./outputs/114hOqbAT6B12wCa_out.png\n",
            "\n",
            "ðŸŽµ usFsg51cRW8XGulk.txt\n",
            "Tags: ['pop', 'rock', 'spanish']\n",
            "Sentiment: NEGATIVE (0.99)\n",
            "Prompt: amor que, enamora que, eres motivo, estamos solas, negative, pop, que solas, rock, spanish\n",
            "[INFO] Image saved to ./outputs/usFsg51cRW8XGulk_out.png\n",
            "\n",
            "ðŸŽµ vtNQ5gvkIEepbiYp.txt\n",
            "Tags: ['pop', 'rock']\n",
            "Sentiment: NEGATIVE (0.98)\n",
            "Prompt: care forever, common regrets, feeling loves, knew loves, negative, pop, regrets, rock\n",
            "[INFO] Image saved to ./outputs/vtNQ5gvkIEepbiYp_out.png\n",
            "\n",
            "ðŸŽµ Yvp0IIDqMZgU4lDm.txt\n",
            "Tags: ['female vocalists', 'pop', 'rock']\n",
            "Sentiment: NEGATIVE (0.99)\n",
            "Prompt: aint hangover, cause sober, female vocalists, ive sober, negative, pop, rock, sober, sober youve\n",
            "[INFO] Image saved to ./outputs/Yvp0IIDqMZgU4lDm_out.png\n",
            "\n",
            "ðŸŽµ IFMdIGm1cpfB1gVT.txt\n",
            "Tags: ['pop', 'rock']\n",
            "Sentiment: NEGATIVE (0.93)\n",
            "Prompt: battle pagan, heart pagan, heathen hold, high pagan, negative, pop, rock\n",
            "[INFO] Image saved to ./outputs/IFMdIGm1cpfB1gVT_out.png\n",
            "\n",
            "ðŸŽµ 5m2FUzgu7VaTEDrC.txt\n",
            "Tags: ['pop']\n",
            "Sentiment: POSITIVE (1.00)\n",
            "Prompt: cause love, girls need, got love, ive love, love, pop, positive\n",
            "[INFO] Image saved to ./outputs/5m2FUzgu7VaTEDrC_out.png\n",
            "\n",
            "ðŸŽµ v2LMYf0Y1rYxTeZq.txt\n",
            "Tags: ['rock']\n",
            "Sentiment: POSITIVE (0.92)\n",
            "Prompt: blood night, darkness, darkness life, eternal night, positive, rock\n",
            "[INFO] Image saved to ./outputs/v2LMYf0Y1rYxTeZq_out.png\n",
            "\n",
            "ðŸŽµ XuV4Suy3SI9mMRcB.txt\n",
            "Tags: ['rock']\n",
            "Sentiment: POSITIVE (0.97)\n",
            "Prompt: aggression sadness, control life, everyday life, life mental, like living, positive, rock\n",
            "[INFO] Image saved to ./outputs/XuV4Suy3SI9mMRcB_out.png\n",
            "\n",
            "ðŸŽµ kERrQTNBHfIcYWra.txt\n",
            "Tags: ['rock']\n",
            "Sentiment: NEGATIVE (1.00)\n",
            "Prompt: beg knees, cold ground, ground make, negative, rock, roots tear, soil\n",
            "[INFO] Image saved to ./outputs/kERrQTNBHfIcYWra_out.png\n",
            "\n",
            "ðŸŽµ w9ZsaLEuQR3IjQD2.txt\n",
            "Tags: ['ambient', 'electronic', 'instrumental', 'soundtrack']\n",
            "Sentiment: POSITIVE (1.00)\n",
            "Prompt: ambient, electronic, instrumental, positive, soundtrack\n",
            "[INFO] Image saved to ./outputs/w9ZsaLEuQR3IjQD2_out.png\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "# Generate Images by Randomly Selecting 10 Lyric Files from ZIP for Model Validation\n",
        "def process_zip(zip_path, extract_dir, pipeline, mlb, top_n=10):\n",
        "    if not os.path.exists(extract_dir):\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "\n",
        "    files = [f for f in os.listdir(extract_dir) if f.endswith(\".txt\")]\n",
        "    selected = random.sample(files, min(top_n, len(files)))\n",
        "\n",
        "    for fname in selected:\n",
        "        with open(os.path.join(extract_dir, fname), \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "        cleaned = clean_text(text)\n",
        "        tags = predict_tags(text, pipeline, mlb)\n",
        "        keywords = extract_keywords(cleaned)\n",
        "        sentiment, score = predict_sentiment(text)\n",
        "\n",
        "        prompt = \", \".join(sorted(set(tags + keywords + [sentiment.lower()])))\n",
        "        out_path = f\"./outputs/{fname.replace('.txt', '_out.png')}\"\n",
        "        os.makedirs(\"./outputs\", exist_ok=True)\n",
        "        print(f\"\\nðŸŽµ {fname}\\nTags: {tags}\\nSentiment: {sentiment} ({score:.2f})\\nPrompt: {prompt}\")\n",
        "        generate_image(prompt, out_path)\n",
        "\n",
        "model_file_id = \"1mU9YVr99C7E5hdys5zPQa5FnvplV8jWv\"\n",
        "pipeline, mlb = load_model(model_file_id)\n",
        "process_zip(\"lyrics.zip\", \"lyrics\", pipeline, mlb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui8qFzbD8lO7",
        "outputId": "cf65c768-68e0-4d0d-bb64-598e904a48c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Model already exists at lyric_classifier_model.pkl, skipping download.\n",
            "[INFO] Model loaded from lyric_classifier_model.pkl\n",
            "\n",
            "ðŸŽµ Demons - Imagine Dragons\n",
            "Tags: ['pop', 'rock']\n",
            "Sentiment: NEGATIVE (0.98)\n",
            "Prompt: breed greed, demons, demons hide, greed kingdom, negative, pop, rock\n",
            "[INFO] Image saved to ./outputs/demons_output.png\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Generate Images Using Lyrics Fetched via API\n",
        "def get_lyrics(song_title, artist, api_key):\n",
        "    url = \"https://api.musixmatch.com/ws/1.1/matcher.lyrics.get\"\n",
        "    params = {\n",
        "        \"apikey\": api_key,\n",
        "        \"q_track\": song_title,\n",
        "        \"q_artist\": artist\n",
        "    }\n",
        "    res = requests.get(url, params=params)\n",
        "    try:\n",
        "        body = res.json()[\"message\"][\"body\"][\"lyrics\"][\"lyrics_body\"]\n",
        "        return body.split(\"...\")[0].strip()\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def process_song(song_title, artist, pipeline, mlb, api_key):\n",
        "    lyrics = get_lyrics(song_title, artist, api_key)\n",
        "    if not lyrics:\n",
        "        print(\"[ERROR] Lyrics not found.\")\n",
        "        return\n",
        "\n",
        "    sentiment, score = predict_sentiment(lyrics)\n",
        "    keywords = extract_keywords(clean_text(lyrics))\n",
        "    tags = predict_tags(lyrics, pipeline, mlb)\n",
        "    prompt = \", \".join(sorted(set(tags + keywords + [sentiment.lower()])))\n",
        "    print(f\"\\nðŸŽµ {song_title} - {artist}\\nTags: {tags}\\nSentiment: {sentiment} ({score:.2f})\\nPrompt: {prompt}\")\n",
        "\n",
        "    out_path = f\"./outputs/{song_title.lower().replace(' ', '_')}_output.png\"\n",
        "    os.makedirs(\"./outputs\", exist_ok=True)\n",
        "    generate_image(prompt, out_path)\n",
        "\n",
        "model_file_id = \"1mU9YVr99C7E5hdys5zPQa5FnvplV8jWv\"\n",
        "pipeline, mlb = load_model(model_file_id)\n",
        "process_song(song_title, artist, pipeline, mlb, api_key=\"api_key\")  # Replace with your actual API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS5JYotx_9Zn",
        "outputId": "79f170d2-5dc9-4cfd-817e-fbb085aa0577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] All .png files in ./outputs have been deleted.\n"
          ]
        }
      ],
      "source": [
        "# # clear outputs images\n",
        "# import os\n",
        "# import glob\n",
        "\n",
        "# for f in glob.glob(\"./outputs/*.png\"):\n",
        "#     os.remove(f)\n",
        "# print(\"[INFO] All .png files in ./outputs have been deleted.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YnYs82BAA4F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
